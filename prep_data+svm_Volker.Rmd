---
title: "R Notebook"
output: html_notebook
---

```{r}
# Importing Function Packages
source("prep_environment.R")
# Importing Datenaufbereitung
source("prep_data.R")

```

```{r}
# alle NAs durch 0 ersetzen, damit die svm läuft
# ist nicht die feine Art, wir müssen uns nochmal genauer um die NAs kümmern.

fullData_dummy[is.na(fullData_dummy)] <- 0
newData[is.na(newData)] <- 0
```



## Splitting Training and Test Data

```{r}
# Setting the random counter to a fixed value, so the random initialization stays the same (the random split is always the same)
set.seed(1)
# Shuffling the dataset (to get random orders within each dataset as well)
new_row_order <- sample(nrow(fullData))
fullData <- fullData_dummy[new_row_order,]
# Assign each row number in the full dataset randomly to one of the three groups of datasets
# The probability of being in one of the groups results then in crresponding group sizes
assignment <- sample(1:2, size = nrow(fullData), prob = c(.9, .1), replace = TRUE)
# Create training and test datasets
train_dataset <- fullData_dummy[assignment == 1, ]  # subset house_pricing to training indices only
test_dataset <- fullData_dummy[assignment == 2, ]  # subset house_pricing to test indices only
```


## Data Preparation

```{r}
# Uncomment the next line if you want to check the correctness of your following code for the svm estimation with a small (and computationally fast) part of the training data set
train_dataset <- sample_frac(train_dataset, .10)
```


## Training the SVM

```{r}
# Optimization of an SVM with standard hyper parameters
# Durch die dummy Variablen sind es mega viele Variablen. Ich weiß nicht, wie man die schöner in die svm gibt. Eine Liste akzeptiert die svm als Input nicht.
model_svm <- svm(Umsatz ~ 
                   Warengruppe_Brot +Warengruppe_Broetchen +Warengruppe_Crossaint +Warengruppe_Konditorei + Warengruppe_Kuchen +Warengruppe_Saisonbrot +
                   Jahr_2013 + Jahr_2014 +Jahr_2015 + Jahr_2016 + Jahr_2017 + Jahr_2018 + Jahr_2019 +
                   Monat_1 + Monat_2 + Monat_3 + Monat_4 + Monat_5 + Monat_6 + Monat_7 + Monat_8 + Monat_9 + Monat_10 + Monat_11 + Monat_12 +
                   Wochentag_Montag + Wochentag_Dienstag + Wochentag_Mittwoch + Wochentag_Donnerstag + Wochentag_Freitag + Wochentag_Samstag + Wochentag_Sonntag+
                   Bewoelkung_1 +  Bewoelkung_2 +  Bewoelkung_3 +  Bewoelkung_4 +  Bewoelkung_5 +  Bewoelkung_6 +  Bewoelkung_7 +  Bewoelkung_8 + 
                   Ferien + Feiertag + Wochenende , train_dataset)
```

```{r}
# Optimization of various SVM using systematically varied hyper parameters (typically called 'grid search' approach) and cross validation
# the resulting object includes the optimal model in the element named 'best.model'
svm_tune <- tune(svm, Umsatz ~ Warengruppe_Brot +Warengruppe_Brötchen +Warengruppe_Crossaint +Warengruppe_Konditorei + Warengruppe_Kuchen +Warengruppe_Saisonbrot +
                   Jahr_2013 + Jahr_2014 +Jahr_2015 + Jahr_2016 + Jahr_2017 + Jahr_2018 + Jahr_2019 +
                   Monat_1 + Monat_2 + Monat_3 + Monat_4 + Monat_5 + Monat_6 + Monat_7 + Monat_8 + Monat_9 + Monat_10 + Monat_11 + Monat_12 +
                   Wochentag_Montag + Wochentag_Dienstag + Wochentag_Mittwoch + Wochentag_Donnerstag + Wochentag_Freitag + Wochentag_Samstag + Wochentag_Sonntag+
                   Bewoelkung_1 +  Bewoelkung_2 +  Bewoelkung_3 +  Bewoelkung_4 +  Bewoelkung_5 +  Bewoelkung_6 +  Bewoelkung_7 +  Bewoelkung_8 + 
                   Ferien + Feiertag + Wochenende , data=train_dataset,
                 ranges = list(epsilon = seq(0.2,1,0.1), cost = 2^(2:3)))

#Auskommentieren, wenn Modell gespeichert werden soll.
#saveRDS(svm_tune, "svm_tune1.rds")
#readRDS("svm_tune1.rds")
```

## Checking the Prediction Quality


### Trainig Data

SVM with a standard hyperparameters
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(model_svm, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$Umsatz, pred_train)
```

SVM with hyperparameters tuned via grid search and cross validation
```{r}
# Calculating the prediction for the training data using the best model according to the grid search
pred_train <- predict(svm_tune$best.model, train_dataset)
# Calculating the prediction quality for the training data using the MAPE
mape(train_dataset$Umsatz, pred_train)
```

### Test Data

SVM with a standard hyperparameters
```{r}
# Calculating the prediction for the validation data using the best model according to the grid search
pred_test <- predict(model_svm, test_dataset)
# Calculating the prediction quality for the validation data using the MAPE
mape(test_dataset$Umsatz, pred_test)
```

SVM with hyperparameters tuned via grid search and cross validation
```{r}
# Calculating the prediction for the test data using the best model according to the grid search
pred_test <- predict(svm_tune$best.model, test_dataset)
# Calculating the prediction quality for the test data using the MAPE
mape(test_dataset$Umsatz, pred_test)
```

### New Data

SVM with a standard hyperparameters
```{r}
# Calculating the prediction for the new data (next day) using the best model according to the grid search
pred_new <- predict(svm_tune$best.model, newData)
pred_new
```
