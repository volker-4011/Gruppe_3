---
title: "Neuronales Netz Prediction"
author: "Peyman Farshidfar, Gerit Imhoff, Pia Fragge, Volker Paatz"
output:
  html_document:
    df_print: paged
---


### Installation von Python und TensorFlow (nur einmalig nötig)
```{r}
#install.packages("reticulate")
library(reticulate)
# Installation von miniconda (falls nicht vorhanden)
#install_miniconda(update=TRUE)
# Anlegen einer speziellen Python Umgebung
#conda_create("r-reticulate", packages = "python=3.6")
# Installieren der Pakete in der angelegten Umgebung
#conda_install("r-reticulate", "pandas")
#conda_install("r-reticulate", "numpy")
#conda_install("r-reticulate", "tensorflow")
#conda_install("r-reticulate", "h5py")
 
# Verwenden der speziellen Python Umgebung die zuvor erstellt wurde
use_condaenv("r-reticulate")
```

### Aufruf des Skripts zur Datenaufbereitung
```{r, include=FALSE}
source("neural-net-data-preparation-gruppe3.R", encoding = "UTF-8")
```


### Laden benötigter Packages
```{r, include=FALSE}
library(reticulate)
library(ggplot2)
library(Metrics)
```


### Definition des Neuronalen Netzes
```{python}
# Import needed Python libraries and functions
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers.experimental import preprocessing

# Create a Normalization layer and use the means and variances of the training features for the normalization
normalizer = preprocessing.Normalization()
normalizer.adapt(r.training_features.values)
# The argument "shape" for the definition of the input layer must include the number of variables (features) used for the model. To automatically calculate this number, we use the "r.training_features.keys()", which returns the list of variable names of the dataframe "training_features". Further, the function len() returns the length of this list of variable names (i.e. the number of variables in the input).
inputs = tf.keras.Input(shape=[len(r.training_features.keys())])
# Normalization layer
x = normalizer(inputs)
# 1st hidden layer
x = Dense(105, activation='relu')(x)
# 2nd hidden layer
x = Dense(4, activation='relu')(x)
# Output layer
output = tf.keras.layers.Dense(1)(x)
# Model definition
model = tf.keras.Model(inputs, output)
# Ausgabe einer Zusammenfassung zur Form des Modells, das geschaetzt wird (nicht notwendig)
model.summary()
```


### Schätzung des neuronalen Netzes
```{python}
# Definition der Kosten-(Loss-)Funktion und der Optimierungsfunktion mit seinen Hyperparametern
model.compile(loss="mse", optimizer=Adam(lr=0.001))
# Schaetzung des Modells
history = model.fit(r.training_features, r.training_labels, epochs=50,
                    validation_data = (r.validation_features, r.validation_labels), verbose=0)
# Ggf. Speichern des geschaetzten Modells
model.save("python_model.h5")
```


### Auswertung der Modelloptimierung
```{r}
# Grafische Ausgabe der Modelloptimierung
# create data
data <- data.frame(val_loss = unlist(py$history$history$val_loss),
                  loss = unlist(py$history$history$loss))
# Plot
ggplot(data[-1,]) +
  geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
  geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
  scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
  labs(title="Loss Function Values During Optimization") +
  xlab("Iteration Number") +
  ylab("Loss") 
```


### (Ggf.) Laden eines gespeicherten Neuronalen Netzes ###
```{python}
model = tf.keras.models.load_model("python_model.h5")
```



### Auswertung der Schätzergebnisse ###
```{r}

# Schätzung der (normierten) Umsätze für die Trainings- und Testdaten
training_predictions <- py$model$predict(training_features)
validation_predictions <- py$model$predict(validation_features)
# Vergleich der Gütekriterien für die Traingings- und Testdaten


cat(paste0("MAPE on the Training Data:\t", format(mape(training_labels[[1]], training_predictions)*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(mape(validation_labels[[1]], validation_predictions)*100, digits=3, nsmall=2)))
```
### Grafischer vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten ###
```{r}

# Zusammenstellung der Daten für die Plots
data_train <- data.frame(prediction = training_predictions/1000, actual = training_labels[[1]]/1000)
data_test <- data.frame(prediction = validation_predictions/1000, actual = validation_labels[[1]]/1000)
# Plot der Ergebnisse der Trainingsdaten
ggplot(data_train[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Training Data") +
  xlab("Case Number") +
  ylab("Umsätze") 
# Plot der Ergebnisse der Validierungsdaten
ggplot(data_test[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Test Data") +
  xlab("Case Number") +
  ylab("Umsätze") 
```

### Vorhersage für einen einzelnen Fall ###
```{r}
cat(paste0("Vorhergesagter Umsatz:\t", round(validation_predictions[100])))
cat(paste0("\nTatsächlicher Umsatz:\t", validation_labels[[1]][100]))
```

### Vorbereiten der Daten zur Vorhersage
```{r}
#Sortieren nach ID, damit die Ausgabe nach Reihenfolge der Warengruppen erfolgt
newData <- newData[order(newData$ID),]
colnamesPred <- colnames(validation_features) #Spalten nach Vorlage der validation_features anpassen
validation_features2 <- newData[colnamesPred] #Spalten nach Vorlage der validation_features anpassen

validation_features2 #Einsicht der 6 Zeilen

#colnamesPred2 <- colnames(training_features)
#training_features2 <- newData[colnamesPred2]
#training_features2
```


### Auswertung der Schätzergebnisse mit Warengruppe 6 ###
```{r}

# Schätzung der (normierten) Umsätze für den neuen Tag über alle Warengruppen
Umsatz_predicted <- py$model$predict(validation_features2)

#Dataframe zur Visualisierung ergänzen
prediction <- data.frame(Umsatz_predicted) 
prediction$Warengruppe <- newData$Warengruppe 
prediction$Datum <- newData$Datum
prediction$Monat <- newData$Monat

#Als CSV speichern
unlink("nne_prediction_1.csv")
    writecsvData <- prediction
    writecsvData <- cbind(ID = 1:nrow(writecsvData), writecsvData)

    write.csv(writecsvData,"nne_prediction_1.csv", append = FALSE, quote = TRUE, sep = ",",
              eol = "\n", na = "NA", dec = ".", row.names = FALSE,
              col.names = TRUE, qmethod = c("escape", "double"),
              fileEncoding = "")
#Einsicht der Ergebnisse
prediction


```
### Grafische Darstellung der Vorhersage mit Warengruppe 6 ###
```{r}
#Einfacher Bar-Plot, zur Darstellung der Umsätze über die Warengruppen 
ggplot(prediction) +
  geom_bar( aes(x=Warengruppe, y=Umsatz_predicted), stat="identity", fill="forestgreen", alpha=0.5)
```



### Auswertung der Schätzergebnisse ohne Warengruppe 6 ###
```{r}
##Da das Saisonbrot nur im Oktober, November oder Dezember verkauft wird, überprüfen, ob sich Vorhersagedatum in dem Zeitraum befindet, ansonsten Umsatz_predicted = 0 setzen
for (i in 1:nrow(prediction)){
  if ((!(prediction$Monat[i]==10 | prediction$Monat[i]==11 | prediction$Monat[i]==12)) & prediction$Warengruppe[i]=="Saisonbrot") {
    prediction$Umsatz_predicted[i] <- 0
  }
}
#Speichern der Vorhergesagten Umsätze als CSV    
unlink("nne_prediction_2.csv")
    writecsvData <- prediction
    writecsvData <- cbind(ID = 1:nrow(writecsvData), writecsvData)

    write.csv(writecsvData,"nne_prediction_2.csv", append = FALSE, quote = TRUE, sep = ",",
              eol = "\n", na = "NA", dec = ".", row.names = FALSE,
              col.names = TRUE, qmethod = c("escape", "double"),
              fileEncoding = "")    
#Einsicht der Ergebnisse
prediction
```

### Grafische Darstellung der Vorhersage ohne Warengruppe 6 ###
```{r}
#Einfacher Bar-Plot, zur Darstellung der Umsätze über die Warengruppen 
ggplot(prediction) +
  geom_bar( aes(x=Warengruppe, y=Umsatz_predicted), stat="identity", fill="forestgreen", alpha=0.5)
```

```{r}

```

### Grafische Darstellung der beiden Vorhersage-Modelle ###
```{r}
#Laden der Ergebnisse der beiden Vorhersagemethoden
nne_prediction <- read_csv("nne_prediction_2.csv")
svm_prediction <- read_csv("svm_prediction_2.csv")
####
#Dataframe bearbeiten
plot_prediction <- svm_prediction
plot_prediction = rename(plot_prediction, Umsatz_SVM = Umsatz_predicted)
#
plot_prediction$Umsatz_NNE <- nne_prediction$Umsatz_predicted
plot_prediction$Umsatz_NNE
####
#str(plot_prediction)

#Zusammensetzen der Dataframes
df1 <- data.frame(Warengruppe=rep(svm_prediction$Warengruppe),
                 Methode=rep('Umsatz_SVM'),
                 Umsatz=svm_prediction$Umsatz_predicted)

df2 <- data.frame(Warengruppe=rep(nne_prediction$Warengruppe),
                 Methode=rep('Umsatz_NNE'),
                 Umsatz=nne_prediction$Umsatz_predicted)

dft <- rbind(df1,df2)
##############################
#Sortieren des Dataframes nach Warengruppen
dft <- dft[order(dft$Warengruppe),]
#Barplot der Ergebnisse separiert
ggplot(dft, aes(fill=Warengruppe, y=Umsatz, x=Methode)) +
  geom_bar(position='dodge', stat='identity')
#Barplot der Ergebnisse nebeneinander
ggplot(dft, aes(fill=Methode, y=Umsatz, x=Warengruppe)) +
  geom_bar(position='dodge', stat='identity') +
  ggtitle('Vorhergesagte Umsätze') +
  xlab('Warengruppen') +
  ylab('Umsatz') +
  scale_fill_manual('Methode', values=c('coral2','steelblue'))
```

### Grafische Darstellung der beiden Vorhersage-Modelle ###
```{r}
#Alternaives Barplot
ggplot(plot_prediction) +
  geom_bar( aes(x=Warengruppe, y=Umsatz_SVM), stat="identity", fill="blue", alpha=0.5) +
  geom_bar( aes(x=Warengruppe, y=Umsatz_NNE), stat="identity", fill="green", alpha=0.5)
```